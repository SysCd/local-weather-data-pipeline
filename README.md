# ğŸŒ¦ï¸ Local Weather Data Pipeline

A complete end-to-end **ETL data pipeline** built entirely on local infrastructure â€” no cloud required.  
This project ingests real-time weather data, processes and transforms it, integrates city metadata, validates data quality, and exposes insights via dashboards and SQL.

---

## ğŸš€ Features

- ğŸŒ **Data Ingestion** â€” Pulls real-time weather data from OpenWeatherMap API
- ğŸ—ƒï¸ **Data Storage** â€” Raw JSON stored locally; processed data in PostgreSQL
- âš™ï¸ **Data Processing** â€” ETL pipeline managed with Apache Airflow
- ğŸ”„ **Data Integration** â€” Combines weather data with city metadata (CSV)
- ğŸ§ª **Data Quality** â€” Validated using Great Expectations
- ğŸ“Š **Data Visualization** â€” Interactive dashboards via Metabase
- ğŸ³ **Containerized** â€” Everything runs locally via Docker

---

## ğŸ› ï¸ Tech Stack

| Layer               | Tool                    |
| ------------------- | ----------------------- |
| Ingestion           | Python + requests       |
| Scheduling          | Apache Airflow          |
| Storage (raw)       | Local File System       |
| Storage (warehouse) | PostgreSQL              |
| Transformation      | dbt                     |
| Data Quality        | Great Expectations      |
| Dashboard           | Metabase                |
| Containerization    | Docker + docker-compose |

---

## ğŸ“ Project Structure

```plaintext
weather_pipeline/
â”œâ”€â”€ airflow/                  # Airflow DAGs and config
â”œâ”€â”€ data/                     # Raw and processed data
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ dbt_project/              # dbt models and configs
â”œâ”€â”€ great_expectations/       # Data validation configs
â”œâ”€â”€ metabase/                 # Optional Metabase config
â”œâ”€â”€ scripts/                  # Data fetch scripts
â”‚   â””â”€â”€ fetch_weather.py
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```
